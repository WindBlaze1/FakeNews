{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Minor Project SEM - 6.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hO7pU9yR4uuN",
        "uQg1mqfB5skZ",
        "0ZobxK5X-DvB",
        "rUfqtCJtzGQv",
        "QGlyAjbHNpUL",
        "po5Oc-DGB8Rq"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Fake News Detection using Deep Learning\n"
      ],
      "metadata": {
        "id": "hxIJLd-b4c14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importing Libraries\n"
      ],
      "metadata": {
        "id": "hO7pU9yR4uuN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsu_ZCfD4XyH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "import re,string,unicodedata\n",
        "from keras.preprocessing import text, sequence\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from string import punctuation\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,LSTM,Dropout\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import Dataset\n"
      ],
      "metadata": {
        "id": "0e_XKsGW49Pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "akfHkF5M5WBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1acd5eeb-f0f7-45ce-cd25-fcc3efc4865d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_data = pd.read_csv('/content/drive/My Drive/dataset/True.csv')\n",
        "fake_data = pd.read_csv('/content/drive/My Drive/dataset/Fake.csv')"
      ],
      "metadata": {
        "id": "MuOnZd2f4_-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Preprocessing:\n",
        "(Same in all):\n",
        "1. Reduce the number of rows to min of both\n",
        "2. Add new field: real_data['category'] = 1, fake_data['category'] = 0\n",
        "3. Merge two datasets\n"
      ],
      "metadata": {
        "id": "uQg1mqfB5skZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "1. Reduce the number of rows to min of both\n",
        "'''\n",
        "print(len(real_data))\n",
        "print(len(fake_data))\n",
        "\n",
        "nb_articles = min(len(real_data), len(fake_data))\n",
        "real_data = real_data[:nb_articles]\n",
        "fake_data = fake_data[:nb_articles]\n",
        "\n",
        "print(len(real_data))\n",
        "print(len(fake_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3ayVXHl6UU7",
        "outputId": "9636678a-0346-4ea5-952d-a1d16e028b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21417\n",
            "23481\n",
            "21417\n",
            "21417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "2. \n",
        "'''\n",
        "real_data['category'] = 1\n",
        "fake_data['category'] = 0"
      ],
      "metadata": {
        "id": "k4bEWQnE6rZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "3.\n",
        "'''\n",
        "df = pd.concat([real_data, fake_data])\n",
        "\n",
        "# Shuffle the data\n",
        "from sklearn.utils import shuffle\n",
        "df = shuffle(df).reset_index(drop=True)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IOaBr96N7CbB",
        "outputId": "a551746e-c1a5-4f93-bcfb-ee5363851255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0   Mark Zuckerberg Brutally SHAMES Trump For Cal...   \n",
              "1   Trump Just Blamed Bombings On ‘Freedom Of The...   \n",
              "2      U.N. nuclear chief to visit Iran this weekend   \n",
              "3   German political rivals agree: No lottery for me   \n",
              "4   This One Car Could Overthrow The Governments ...   \n",
              "\n",
              "                                                text    subject  \\\n",
              "0  Recently, President Bannon s underling, Donald...       News   \n",
              "1  Donald Trump appeared on Fox & Friends Monday ...       News   \n",
              "2  VIENNA (Reuters) - The head of the United Nati...  worldnews   \n",
              "3  BERLIN (Reuters) - German Chancellor Angela Me...  worldnews   \n",
              "4  For more than a century, countries around the ...       News   \n",
              "\n",
              "                  date  category  \n",
              "0    February 21, 2017         0  \n",
              "1   September 19, 2016         0  \n",
              "2    October 25, 2017          1  \n",
              "3  September 22, 2017          1  \n",
              "4        April 1, 2016         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73208d54-c62e-4f19-ae0b-00150e01255d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mark Zuckerberg Brutally SHAMES Trump For Cal...</td>\n",
              "      <td>Recently, President Bannon s underling, Donald...</td>\n",
              "      <td>News</td>\n",
              "      <td>February 21, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Trump Just Blamed Bombings On ‘Freedom Of The...</td>\n",
              "      <td>Donald Trump appeared on Fox &amp; Friends Monday ...</td>\n",
              "      <td>News</td>\n",
              "      <td>September 19, 2016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>U.N. nuclear chief to visit Iran this weekend</td>\n",
              "      <td>VIENNA (Reuters) - The head of the United Nati...</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>October 25, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>German political rivals agree: No lottery for me</td>\n",
              "      <td>BERLIN (Reuters) - German Chancellor Angela Me...</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>September 22, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This One Car Could Overthrow The Governments ...</td>\n",
              "      <td>For more than a century, countries around the ...</td>\n",
              "      <td>News</td>\n",
              "      <td>April 1, 2016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73208d54-c62e-4f19-ae0b-00150e01255d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73208d54-c62e-4f19-ae0b-00150e01255d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73208d54-c62e-4f19-ae0b-00150e01255d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Preprocessing\n",
        "Remaining Steps: (common for Kartik and Sparsh):\n",
        "4. text = text + title\n",
        "5. Data Cleaning\n",
        "6. Data Analysis\n",
        "7. Word Cloud"
      ],
      "metadata": {
        "id": "rwJB9Xk4UPOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "df['text'] = df['text'] + \" \" + df['title']\n",
        "del df['title']\n",
        "del df['subject']\n",
        "del df['date']"
      ],
      "metadata": {
        "id": "jv-tM-ytUSyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Data Cleaning:\n",
        "\n",
        "# stop-words:\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop = set(stopwords.words('english'))\n",
        "punctuation = list(string.punctuation)\n",
        "stop.update(punctuation)\n",
        "\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "# Removing URL's\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub(r'http\\S+', '', text)\n",
        "#Removing the stopwords from text\n",
        "def remove_stopwords(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stop:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    text = remove_stopwords(text)\n",
        "    return text\n",
        "#Apply function on review column\n",
        "df['text']=df['text'].apply(denoise_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65LqDkbkVDlx",
        "outputId": "3f05d358-4092-4393-e016-ab1b7825c244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "u2QCHcOZVJhp",
        "outputId": "e5ba88ed-59ff-4ce2-d1dd-2879cf06221c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  category\n",
              "0  really hard LGBT community welcome Caitlyn Jen...         0\n",
              "1  never young commit jihad Teachers primary scho...         0\n",
              "2  Donald Trump might try tell American voters ch...         0\n",
              "3  President Obama obviously disappointed Donald ...         0\n",
              "4  BELGRADE (Reuters) British Foreign Secretary B...         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53bbcbd4-70f8-4d56-aa20-cbff4313528d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>really hard LGBT community welcome Caitlyn Jen...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>never young commit jihad Teachers primary scho...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Donald Trump might try tell American voters ch...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>President Obama obviously disappointed Donald ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BELGRADE (Reuters) British Foreign Secretary B...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53bbcbd4-70f8-4d56-aa20-cbff4313528d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53bbcbd4-70f8-4d56-aa20-cbff4313528d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53bbcbd4-70f8-4d56-aa20-cbff4313528d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Data Analysis"
      ],
      "metadata": {
        "id": "cn2QRxIvnT_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Data Analysis:\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "def get_top_text_ngrams(corpus, n, g):\n",
        "    vec = CountVectorizer(ngram_range=(g, g)).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]"
      ],
      "metadata": {
        "id": "qCP9f4odVjox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unigram:\n",
        "plt.figure(figsize = (16,9))\n",
        "most_common_uni = get_top_text_ngrams(df.text,10,1)\n",
        "most_common_uni = dict(most_common_uni)\n",
        "sns.barplot(x=list(most_common_uni.values()),y=list(most_common_uni.keys()))"
      ],
      "metadata": {
        "id": "CflGgl2WnakE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bigram:\n",
        "plt.figure(figsize = (16,9))\n",
        "most_common_bi = get_top_text_ngrams(df.text,10,2)\n",
        "most_common_bi = dict(most_common_bi)\n",
        "sns.barplot(x=list(most_common_bi.values()),y=list(most_common_bi.keys()))"
      ],
      "metadata": {
        "id": "6Qe95ocHnd18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Trigram:\n",
        "plt.figure(figsize = (16,9))\n",
        "most_common_tri = get_top_text_ngrams(df.text,10,3)\n",
        "most_common_tri = dict(most_common_tri)\n",
        "sns.barplot(x=list(most_common_tri.values()),y=list(most_common_tri.keys()))"
      ],
      "metadata": {
        "id": "Uxnqnqt3nhOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WORDCLOUD FOR REAL TEXT (LABEL - 1)\n",
        "plt.figure(figsize = (20,20)) # Text that is not Fake\n",
        "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800 , stopwords = STOPWORDS).generate(\" \".join(df[df.category == 1].text))\n",
        "plt.imshow(wc , interpolation = 'bilinear')"
      ],
      "metadata": {
        "id": "KJDLyQuiuaxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WORDCLOUD FOR FAKE TEXT (LABEL - 0)\n",
        "plt.figure(figsize = (20,20)) # Text that is Fake\n",
        "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800 , stopwords = STOPWORDS).generate(\" \".join(df[df.category == 0].text))\n",
        "plt.imshow(wc , interpolation = 'bilinear')"
      ],
      "metadata": {
        "id": "xVYuaT-5wpQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Embeddings"
      ],
      "metadata": {
        "id": "Z8Ua0D0RzDIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###TF-IDF"
      ],
      "metadata": {
        "id": "rUfqtCJtzGQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tfidf = df.copy()"
      ],
      "metadata": {
        "id": "7GOQMdrukhLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating stemmed and lemmatized text for applying TF-IDF:\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "porter_stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "stemmed_text = []\n",
        "lemmatized_text = []\n",
        "final_text_result = []\n",
        "for text in df_tfidf['text']:\n",
        "    result = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    # result = result.lower()\n",
        "    result = result.split()\n",
        "    # result = [r for r in result if r not in set(stopwords.words('english'))]\n",
        "    stemmed_result = [porter_stemmer.stem(r) for r in result]\n",
        "    stemmed_text.append(\" \".join(stemmed_result))\n",
        "    lemmatized_result = [lemmatizer.lemmatize(r) for r in result]\n",
        "    lemmatized_text.append(\" \".join(lemmatized_result))\n",
        "\n",
        "print(len(stemmed_text))\n",
        "print(len(lemmatized_text))"
      ],
      "metadata": {
        "id": "sFiNDr3NzIGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b08eb3a2-4c6b-478e-c716-50f0ae5b0e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "42834\n",
            "42834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to print confusion matrix and accuracy score:\n",
        "def get_prediction(vectorizer, classifier, X_train, X_test, y_train, y_test):\n",
        "    pipe = Pipeline([('vector', vectorizer),\n",
        "                    ('model', classifier)])\n",
        "    model = pipe.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(\"Accuarcy: {}\".format(round(accuracy_score(y_test, y_pred)*100,2)))\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion Matrix: \\n\", cm)\n",
        "    print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "cySeMBD6m4bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Classifiers:\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "Ti3UmQiBp4F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# TF-IDF Vectorizer:\n",
        "\n",
        "# here we are taking only top 5000 words from the news\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "# TF-IDF feature matrix:\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(stemmed_text)\n",
        "X_tfidf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItzZmeKkB_xA",
        "outputId": "a30c6977-8c8f-41b1-cb21-d38054eb48da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42834, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the target variable\n",
        "y_tfidf = df_tfidf['category']\n",
        "\n",
        "# Divide the dataset into Train and Test\n",
        "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, y_tfidf, test_size=0.25, random_state=0)"
      ],
      "metadata": {
        "id": "Xrg2tSthIrRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####One hot for Embedding layers and Padding\n"
      ],
      "metadata": {
        "id": "QGlyAjbHNpUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#Setting up vocabulary size\n",
        "voc_size = 10000\n",
        "\n",
        "#One hot encoding \n",
        "onehot_repr_tfidf = [one_hot(words,voc_size)for words in stemmed_text] \n",
        "\n",
        "# Padding embedded documents - to make the length of all sentences equal\n",
        "# Setting sentence length\n",
        "sent_length=5000\n",
        "\n",
        "#Padding the sentences\n",
        "embedded_docs_tfidf = pad_sequences(onehot_repr_tfidf, padding='pre', maxlen = sent_length)\n",
        "print(embedded_docs_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv7iOvZmNu2F",
        "outputId": "0c4ad75f-f1b7-406c-8ebf-b5eaf846c05e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0 ... 3856 7381 5950]\n",
            " [   0    0    0 ... 2675 1238 3132]\n",
            " [   0    0    0 ... 4997 8851 9290]\n",
            " ...\n",
            " [   0    0    0 ... 2223 2837 5445]\n",
            " [   0    0    0 ... 3024  885 5559]\n",
            " [   0    0    0 ... 7861 4250 2460]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TF-IDF Vectorizer"
      ],
      "metadata": {
        "id": "KP-1FDSYs1_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LSTM\n"
      ],
      "metadata": {
        "id": "2fpx9CRC7nyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the lstm model\n",
        "embedding_vector_features=40\n",
        "model=Sequential()\n",
        "model.add(Embedding(voc_size, embedding_vector_features, input_length = sent_length))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(100)) #Adding 100 lstm neurons in the layer\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "#Compiling the model\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKIkQSH87pdZ",
        "outputId": "bb31c56d-85d5-4a9a-f63b-fb4cafeefba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 5000, 40)          400000    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 5000, 40)          0         \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 100)               56400     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 456,501\n",
            "Trainable params: 456,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the LSTM Model\n",
        "# Converting the X and y as array\n",
        "X_tfidf_lstm = np.array(embedded_docs_tfidf)\n",
        "y_tfidf_lstm = np.array(y_tfidf)\n",
        "\n",
        "#Check shape of X and y final\n",
        "X_tfidf_lstm.shape, y_tfidf_lstm.shape\n",
        "\n",
        "# Train test split of the X and y final\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_lstm, y_tfidf_lstm, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "1f3TaA3w8Y4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting with 10 epochs and 64 batch size\n",
        "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=5,batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrmQrQz687pP",
        "outputId": "fc21a0d5-6649-49da-fb79-fad467d47e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "449/449 [==============================] - 113s 248ms/step - loss: 0.1235 - accuracy: 0.9538 - val_loss: 0.0508 - val_accuracy: 0.9827\n",
            "Epoch 2/5\n",
            "449/449 [==============================] - 120s 267ms/step - loss: 0.0268 - accuracy: 0.9923 - val_loss: 0.0572 - val_accuracy: 0.9826\n",
            "Epoch 3/5\n",
            "449/449 [==============================] - 129s 287ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 0.0275 - val_accuracy: 0.9914\n",
            "Epoch 4/5\n",
            "449/449 [==============================] - 115s 255ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.0301 - val_accuracy: 0.9919\n",
            "Epoch 5/5\n",
            "449/449 [==============================] - 114s 254ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.0367 - val_accuracy: 0.9881\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe7246b8b50>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Evaluation of LSTM"
      ],
      "metadata": {
        "id": "po5Oc-DGB8Rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting from test data\n",
        "# tf.sparse.reorder(sp_input)\n",
        "y_pred_tfidf = model.predict(X_test_tfidf)\n",
        "y_classes_tfidf = np.argmax(y_pred_tfidf, axis=1)\n",
        "\n",
        "#Creating confusion matrix\n",
        "#confusion_matrix(y_test,y_pred)\n",
        "cm = metrics.confusion_matrix(y_test_tfidf, y_pred_tfidf)\n",
        "plot_confusion_matrix(cm,classes=['Fake','True'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "q7x_ILqcB_jR",
        "outputId": "b048a54a-cd07-4fc3-9baa-0e33d39f825e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-3f84f2ad606b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predicting from test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# tf.sparse.reorder(sp_input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_pred_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_classes_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7186\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[2] = [0,518] is out of order. Many sparse ops require sorted indices.\n    Use `tf.sparse.reorder` to create a correctly ordered copy.\n\n [Op:SerializeManySparse]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###RNN Model"
      ],
      "metadata": {
        "id": "iUftDlmGJhWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_RNN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(voc_size, 128),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_RNN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6itGMU9pJkHs",
        "outputId": "4d18fd0f-20df-4adc-f2d8-61d36e42d50e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 128)         1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 128)        98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 32)               18560     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,399,553\n",
            "Trainable params: 1,399,553\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We are going to use early stop, which stops when the validation loss no longer improve\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "model_RNN.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history_RNN_tfidf = model_RNN.fit(X_train, y_train, epochs=10,validation_data=(X_test,y_test), batch_size=30, shuffle=True, callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEoXk61bTQMZ",
        "outputId": "222970ba-bfab-4f0d-a91b-ba774b781329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "957/957 [==============================] - 566s 586ms/step - loss: 0.2055 - accuracy: 0.9030 - val_loss: 0.0347 - val_accuracy: 0.9924\n",
            "Epoch 2/10\n",
            "957/957 [==============================] - 565s 590ms/step - loss: 0.0323 - accuracy: 0.9933 - val_loss: 0.0376 - val_accuracy: 0.9883\n",
            "Epoch 3/10\n",
            "957/957 [==============================] - 563s 589ms/step - loss: 0.0179 - accuracy: 0.9962 - val_loss: 0.0212 - val_accuracy: 0.9949\n",
            "Epoch 4/10\n",
            "957/957 [==============================] - 571s 596ms/step - loss: 0.0085 - accuracy: 0.9988 - val_loss: 0.0192 - val_accuracy: 0.9953\n",
            "Epoch 5/10\n",
            "957/957 [==============================] - 572s 598ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.0185 - val_accuracy: 0.9955\n",
            "Epoch 6/10\n",
            "957/957 [==============================] - 572s 598ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.0223 - val_accuracy: 0.9957\n",
            "Epoch 7/10\n",
            "957/957 [==============================] - 573s 598ms/step - loss: 0.0083 - accuracy: 0.9986 - val_loss: 0.0317 - val_accuracy: 0.9922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Visualize our training over time (RNN)"
      ],
      "metadata": {
        "id": "yHlJHeZvPmq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict_RNN_tfidf = history_RNN_tfidf.history\n",
        "\n",
        "acc = history_dict_RNN_tfidf['accuracy']\n",
        "val_acc = history_dict_RNN_tfidf['val_accuracy']\n",
        "loss = history_dict_RNN_tfidf['loss']\n",
        "val_loss = history_dict_RNN_tfidf['val_loss']\n",
        "epochs = history_RNN_tfidf.epoch\n",
        "\n",
        "plt.figure(figsize=(12,9))\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss', size=20)\n",
        "plt.xlabel('Epochs', size=20)\n",
        "plt.ylabel('Loss', size=20)\n",
        "plt.legend(prop={'size': 20})\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12,9))\n",
        "plt.plot(epochs, acc, 'g', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy', size=20)\n",
        "plt.xlabel('Epochs', size=20)\n",
        "plt.ylabel('Accuracy', size=20)\n",
        "plt.legend(prop={'size': 20})\n",
        "plt.ylim((0.5,1))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "txgF6R2jPqNp",
        "outputId": "6ae7e809-7e5e-4e7f-f766-f2380beed8aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CNN"
      ],
      "metadata": {
        "id": "QzeeBXZn3LfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model:\n",
        "model_CNN = Sequential()\n",
        "model_CNN.add(Dense(units = 100 , activation = 'relu' , input_dim = X_tfidf.shape[1]))\n",
        "model_CNN.add(Dense(units = 50 , activation = 'relu'))\n",
        "model_CNN.add(Dense(units = 25 , activation = 'relu'))\n",
        "model_CNN.add(Dense(units = 10 , activation = 'relu'))\n",
        "model_CNN.add(Dense(units = 1 , activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "gJ1JgNiX3OsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model:\n",
        "model_CNN.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "cYPALAG9___0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_CNN.fit(X_train,y_train , epochs = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN5fLNIXAIVI",
        "outputId": "2e2576e4-be7e-4650-94b6-ecb9efaa7007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "897/897 [==============================] - 4s 3ms/step - loss: 1.8875 - accuracy: 0.4974\n",
            "Epoch 2/5\n",
            "897/897 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4981\n",
            "Epoch 3/5\n",
            "897/897 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4989\n",
            "Epoch 4/5\n",
            "897/897 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4992\n",
            "Epoch 5/5\n",
            "897/897 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4974\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe875d6fb90>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Prediction - CNN"
      ],
      "metadata": {
        "id": "xJOScnwlAZIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_tfidf_CNN = model_CNN.predict(X_test)\n",
        "print(pred_tfidf_CNN)\n",
        "prede_tfidf_CNN = list()\n",
        "for i in range(len(pred_tfidf_CNN)):\n",
        "    if(pred_tfidf_CNN[i] > 0.5):\n",
        "        prede_tfidf_CNN.append(1)\n",
        "    else:\n",
        "        prede_tfidf_CNN.append(0)\n",
        "print(prede_tfidf_CNN)\n",
        "accuracy_score(prede_tfidf_CNN,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPLiYNvHAYYw",
        "outputId": "57ef0a34-5898-4003-c8e9-34fee3ed604a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.49662206]\n",
            " [0.49662206]\n",
            " [0.49662206]\n",
            " ...\n",
            " [0.49662206]\n",
            " [0.49662206]\n",
            " [0.49662206]]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49787775891341257"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Evaluation of CNN"
      ],
      "metadata": {
        "id": "kpuqenLOAyUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_cnn_report = classification_report(y_test,pred_tfidf_CNN,target_names = ['0','1'])\n",
        "print(tfidf_cnn_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P_0MT25AxDt",
        "outputId": "33a08ae5-8a37-4897-d17b-ec6fda7553ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.66      7038\n",
            "           1       0.00      0.00      0.00      7098\n",
            "\n",
            "    accuracy                           0.50     14136\n",
            "   macro avg       0.25      0.50      0.33     14136\n",
            "weighted avg       0.25      0.50      0.33     14136\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Confusion Matrix for CNN"
      ],
      "metadata": {
        "id": "VCv4tLK2BAdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm_tfidf_cnn = confusion_matrix(y_test,pred_tfidf_CNN)\n",
        "cm_tfidf_cnn = pd.DataFrame(cm_tfidf_cnn, index=[0,1], columns=[0,1])\n",
        "cm_tfidf_cnn.index.name = 'Actual'\n",
        "cm_tfidf_cnn.columns.name = 'Predicted'\n",
        "plt.figure(figsize = (10,10))\n",
        "sns.heatmap(cm_tfidf_cnn,cmap= \"Blues\",annot = True, fmt='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "Pn3VLAIuBEmr",
        "outputId": "f7e07c6b-5e4c-4ea8-a9ed-b2841a2c7145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe84e203d10>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Glove\n"
      ],
      "metadata": {
        "id": "L4-wFOhpe13H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_glove = df.copy()"
      ],
      "metadata": {
        "id": "DF1dyVGae4K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(df_glove.text,df_glove.category,random_state = 0)\n",
        "max_features = 10000\n",
        "maxlen = 300"
      ],
      "metadata": {
        "id": "8-cxPjNbe9td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = text.Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "tokenized_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_train = sequence.pad_sequences(tokenized_train, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "vorl4NJ2mAIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_test = tokenizer.texts_to_sequences(x_test)\n",
        "X_test = sequence.pad_sequences(tokenized_test, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "M8RNkDRwmHxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_FILE = '/content/drive/My Drive/dataset/glove.twitter.27B.100d.txt'"
      ],
      "metadata": {
        "id": "-uiy31K2Wqhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_coefs(word, *arr): \n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))"
      ],
      "metadata": {
        "id": "stoOwhvnKsD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "#change below line if computing normal stats is too slow\n",
        "embedding_matrix = embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "QNPd4Bu2KulE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f7ae5f-6e86-43fb-e00d-ac69e125d301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a copy of train and test data for genetic:\n",
        "x_test_ga = X_test\n",
        "x_train_ga = x_train\n",
        "y_ga = y_train"
      ],
      "metadata": {
        "id": "0h2jBgrYqWQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM on Glove"
      ],
      "metadata": {
        "id": "GRjHK6VykqGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "epochs = 1\n",
        "embed_size = 100"
      ],
      "metadata": {
        "id": "HDhpndVdKvKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)"
      ],
      "metadata": {
        "id": "5au9-zOVKyb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining Neural Network\n",
        "model = Sequential()\n",
        "#Non-trainable embeddidng layer\n",
        "model.add(Embedding(max_features, output_dim=embed_size, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
        "#LSTM \n",
        "model.add(LSTM(units=128 , return_sequences = True , recurrent_dropout = 0.25 , dropout = 0.25))\n",
        "model.add(LSTM(units=64 , recurrent_dropout = 0.1 , dropout = 0.1))\n",
        "model.add(Dense(units = 32 , activation = 'relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr = 0.01), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3VNY3wdAK0GL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef5c9d09-9395-422f-e1a0-1bccac9ce579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Oqs7yfNOK0p5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1995298-163e-4bb6-a2f5-893f61f9591b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 300, 100)          1000000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 300, 128)          117248    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,168,769\n",
            "Trainable params: 168,769\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, batch_size = batch_size , validation_data = (X_test,y_test) , epochs = epochs , callbacks = [learning_rate_reduction])"
      ],
      "metadata": {
        "id": "D1VJ-dVUK9w8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aebaeb7c-6885-4e9b-b768-269ed9c9c479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 333s 3s/step - loss: 0.1201 - accuracy: 0.9548 - val_loss: 0.0260 - val_accuracy: 0.9911 - lr: 0.0100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy of the model on Training Data is - \" , model.evaluate(x_train,y_train)[1]*100 , \"%\")\n",
        "print(\"Accuracy of the model on Testing Data is - \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")"
      ],
      "metadata": {
        "id": "psMSZDqZK_vL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "7e9361e8-0786-4ed4-f83c-ec2eca1f5502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 566/1004 [===============>..............] - ETA: 1:09 - loss: 0.0248 - accuracy: 0.9919"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-972d23974b8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy of the model on Training Data is - \"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy of the model on Testing Data is - \"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = [i for i in range(10)]\n",
        "fig , ax = plt.subplots(1,2)\n",
        "train_acc = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "fig.set_size_inches(20,10)\n",
        "\n",
        "ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n",
        "ax[0].plot(epochs , val_acc , 'ro-' , label = 'Testing Accuracy')\n",
        "ax[0].set_title('Training & Testing Accuracy')\n",
        "ax[0].legend()\n",
        "ax[0].set_xlabel(\"Epochs\")\n",
        "ax[0].set_ylabel(\"Accuracy\")\n",
        "\n",
        "ax[1].plot(epochs , train_loss , 'go-' , label = 'Training Loss')\n",
        "ax[1].plot(epochs , val_loss , 'ro-' , label = 'Testing Loss')\n",
        "ax[1].set_title('Training & Testing Loss')\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel(\"Epochs\")\n",
        "ax[1].set_ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bAsNiqXdLGsK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "outputId": "e3d26ac3-9352-46ee-e9fd-a800a529fe34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-8aa88a7e6a27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_size_inches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'go-'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Training Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'ro-'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Testing Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training & Testing Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (1,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "9a3GCt6wLINN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classe_x = list()\n",
        "for i in pred:\n",
        "  if i[0] >= 0.5:\n",
        "    classe_x.append(1)\n",
        "  else:\n",
        "    classe_x.append(0)\n",
        "classe_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73weYBCdzZwY",
        "outputId": "d81b6c9f-0081-496e-804b-af93263aa8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, classe_x, target_names = ['Fake','Not Fake']))"
      ],
      "metadata": {
        "id": "vuQF3KYeLJef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5192164b-6ff1-498a-c08f-29b18708b83c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.99      0.99      0.99      5360\n",
            "    Not Fake       0.99      0.99      0.99      5349\n",
            "\n",
            "    accuracy                           0.99     10709\n",
            "   macro avg       0.99      0.99      0.99     10709\n",
            "weighted avg       0.99      0.99      0.99     10709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, classe_x)\n",
        "cm"
      ],
      "metadata": {
        "id": "4hHpyi3bLK5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "770606ff-8079-481c-fc3b-5d753d6f6d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5320,   40],\n",
              "       [  55, 5294]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = pd.DataFrame(cm , index = ['Fake','Original'] , columns = ['Fake','Original'])\n",
        "cm"
      ],
      "metadata": {
        "id": "w46jUalpLL_J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "53a9ebfd-0071-4378-b17e-88784a777eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Fake  Original\n",
              "Fake      5320        40\n",
              "Original    55      5294"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-748cedc6-b137-4681-9011-27644fe39988\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fake</th>\n",
              "      <th>Original</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Fake</th>\n",
              "      <td>5320</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Original</th>\n",
              "      <td>55</td>\n",
              "      <td>5294</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-748cedc6-b137-4681-9011-27644fe39988')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-748cedc6-b137-4681-9011-27644fe39988 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-748cedc6-b137-4681-9011-27644fe39988');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "sns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='' , xticklabels = ['Fake','Original'] , yticklabels = ['Fake','Original'])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")"
      ],
      "metadata": {
        "id": "oMz5CLt9LNlE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "d35489f3-1318-4a79-ae32-aefa813f2383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(69.0, 0.5, 'Actual')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RNN on Glove"
      ],
      "metadata": {
        "id": "QGSVao3dkvor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voc_size = 10000\n",
        "model_RNN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(voc_size, 128),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_RNN.summary()"
      ],
      "metadata": {
        "id": "rRlwCg6Zfh0t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40c0ea58-8699-41b0-aab1-b14b6e0afa00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 128)         1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 128)        98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 32)               18560     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,399,553\n",
            "Trainable params: 1,399,553\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(data):\n",
        "    normalized = []\n",
        "    for i in data:\n",
        "        i = i.lower()\n",
        "        # get rid of urls\n",
        "        i = re.sub('https?://\\S+|www\\.\\S+', '', i)\n",
        "        # get rid of non words and extra spaces\n",
        "        i = re.sub('\\\\W', ' ', i)\n",
        "        i = re.sub('\\n', '', i)\n",
        "        i = re.sub(' +', ' ', i)\n",
        "        i = re.sub('^ ', '', i)\n",
        "        i = re.sub(' $', '', i)\n",
        "        normalized.append(i)\n",
        "    return normalized\n",
        "\n",
        "x_train = normalize(x_train)\n",
        "x_test = normalize(x_test)"
      ],
      "metadata": {
        "id": "g5KQaZfL8nGQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "72d5571c-bf38-4720-8aef-8b333e5e456e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-38a09395c476>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-38a09395c476>\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnormalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;31m# get rid of urls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https?://\\S+|www\\.\\S+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "UmK4G_tb86lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab = 10000\n",
        "tokenizer = Tokenizer(num_words=max_vocab)\n",
        "tokenizer.fit_on_texts(x_train)"
      ],
      "metadata": {
        "id": "lcjRDmDd82xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tokenizer.texts_to_sequences(x_train)\n",
        "X_test = tokenizer.texts_to_sequences(x_test)"
      ],
      "metadata": {
        "id": "uIdBEF2G9PBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, padding='post', maxlen=256)\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, padding='post', maxlen=256)"
      ],
      "metadata": {
        "id": "DA5hxpQB9YN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_RNN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(max_vocab, 128),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_RNN.summary()"
      ],
      "metadata": {
        "id": "FGWZd1nn9g2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We are going to use early stop, which stops when the validation loss no longer improve\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "model_RNN.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history_RNN_glove = model_RNN.fit(X_train, y_train, epochs=1,validation_data=(x_test,y_test), batch_size=30, shuffle=True, callbacks=[early_stop])"
      ],
      "metadata": {
        "id": "ns33r9dik4qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate(ga_individual_solution):  \n",
        "    \n",
        "    # Decode the Genetic Algorithm solution to get the window size and number of bits\n",
        "    window_size_bits = BitArray(ga_individual_solution[0:6])\n",
        "    num_units_bits = BitArray(ga_individual_solution[6:]) \n",
        "    window_size = window_size_bits.uint\n",
        "    num_of_units = num_units_bits.uint\n",
        "    print('\\nWindow Size: ', window_size, ', Num of Units: ', num_of_units)\n",
        "    \n",
        "    # Return fitness score of 100 if window_size or num_unit is zero\n",
        "    if window_size == 0 or num_of_units == 0:\n",
        "        return 100, \n",
        "    \n",
        "    # Segment the train_data based on new window_size; \n",
        "    # Split the dataset into train set(80) and validation set(20)\n",
        "    X_data,Y_data = prepare_dataset(x_train,window_size)\n",
        "    X_train, X_val, y_train, y_val = split(X_data, Y_data, test_size = 0.20, random_state = 1120)\n",
        "    \n",
        "    # Design an LSTM model to train on training data and predict on validation data\n",
        "    input_ph = Input(shape=(window_size,1))\n",
        "    x = LSTM(num_of_units, input_shape=(window_size,1))(input_ph)\n",
        "    predicted_values = Dense(1, activation='tanh')(x)\n",
        "    model = Model(inputs=input_ph, outputs=predicted_values)\n",
        "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=20,shuffle=True)\n",
        "    y_pred = model.predict(X_val)\n",
        "    \n",
        "    # Calculate the RMSE score as fitness score for GA\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    print('Validation RMSE: ', rmse,'\\n')\n",
        "    \n",
        "    return rmse"
      ],
      "metadata": {
        "id": "-8OiArp3d7BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(data, window_size):\n",
        "    X, Y = np.empty((0,window_size)), np.empty((0))\n",
        "    for i in range(len(data)-window_size-1):\n",
        "        X = np.vstack([X,data[i:(i + window_size),0]])\n",
        "        Y = np.append(Y,data[i + window_size,0])   \n",
        "    X = np.reshape(X,(len(X),window_size,1))\n",
        "    Y = np.reshape(Y,(len(Y),1))\n",
        "    return X, Y\n",
        "\n",
        "population_size = 4\n",
        "num_generations = 4\n",
        "gene_length = 10\n",
        "\n",
        "#Implementation of Genetic Algorithm using DEAP python library.\n",
        "\n",
        "#Since we try to minimise the loss values, we use the negation of the root mean squared loss as fitness function.\n",
        "creator.create('FitnessMax', base.Fitness, weights = (-1.0,))\n",
        "creator.create('Individual', list , fitness = creator.FitnessMax)\n",
        "\n",
        "#initialize the variables as bernoilli random variables\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register('binary', bernoulli.rvs, 0.5)\n",
        "toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
        "toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
        "\n",
        "#Ordered cross-over used for mating\n",
        "toolbox.register('mate', tools.cxOrdered)\n",
        "#Shuffle mutation to reorder the chromosomes\n",
        "toolbox.register('mutate', tools.mutShuffleIndexes, indpb = 0.6)\n",
        "#use roulette wheel selection algorithm\n",
        "toolbox.register('select', tools.selRoulette)\n",
        "#training function used for evaluating fitness of individual solution.\n",
        "toolbox.register('evaluate', train_evaluate)\n",
        "\n",
        "population = toolbox.population(n = population_size)\n",
        "r = algorithms.eaSimple(population, toolbox, cxpb = 0.4, mutpb = 0.1, ngen = num_generations, verbose = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "7bLp_zTseIND",
        "outputId": "9803c348-15ec-4dc6-e948-a5e163ff7e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  RuntimeWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Window Size:  37 , Num of Units:  12\n",
            "Epoch 1/5\n",
            "1284/1284 [==============================] - 8s 4ms/step - loss: 1554564.8750\n",
            "Epoch 2/5\n",
            "1284/1284 [==============================] - 6s 4ms/step - loss: 1554539.2500\n",
            "Epoch 3/5\n",
            "1284/1284 [==============================] - 8s 6ms/step - loss: 1554539.7500\n",
            "Epoch 4/5\n",
            "1284/1284 [==============================] - 8s 6ms/step - loss: 1554539.1250\n",
            "Epoch 5/5\n",
            "1284/1284 [==============================] - 6s 4ms/step - loss: 1554539.5000\n",
            "Validation RMSE:  1173.2752533631021 \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-5c9d0a2f959e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopulation_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meaSimple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcxpb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutpb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_generations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deap/algorithms.py\u001b[0m in \u001b[0;36meaSimple\u001b[0;34m(population, toolbox, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhalloffame\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deap/base.py\u001b[0m in \u001b[0;36msetValues\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Assigned values have not the same length than fitness weights\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_individuals_data = tools.selBest(population,k = 1) #select top 1 solution\n",
        "optimal_window_size = None\n",
        "optimal_num_units = None\n",
        "\n",
        "for bi in optimal_individuals_data:\n",
        "    window_size_bits = BitArray(bi[0:6])\n",
        "    num_units_bits = BitArray(bi[6:]) \n",
        "    optimal_window_size = window_size_bits.uint\n",
        "    optimal_num_units = num_units_bits.uint\n",
        "    print('\\n Best Window Size: ', optimal_window_size, ', Best Num of Units: ', optimal_num_units)\n",
        "\n",
        "#print(optimal_window_size, optimal_num_units)"
      ],
      "metadata": {
        "id": "DTgndrCkgA02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.layers import LSTM, Input, Dense\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split as split\n",
        "!pip install deap\n",
        "from deap import base, creator, tools, algorithms\n",
        "from keras.models import Model\n",
        "from scipy.stats import bernoulli\n",
        "#import tflearn\n",
        "#from tflearn.metrics import Accuracy\n",
        "!pip install bitstring\n",
        "from bitstring import BitArray\n",
        "\n",
        "np.random.seed(1120)\n",
        "\n",
        "def prepare(data, win_size):\n",
        "    A, B = np.empty((0,win_size)), np.empty((0))\n",
        "    for i in range(len(data)-win_size-1):\n",
        "        A = np.vstack([A,data[i:(i + win_size),0]])\n",
        "        B = np.append(B,data[i + win_size,0])   \n",
        "    A = np.reshape(A,(len(A),win_size,1))\n",
        "    B = np.reshape(B,(len(B),1))\n",
        "    return A, B\n",
        "\n",
        "def evaluate(ga_sol):       \n",
        "    win_size_bits = BitArray(ga_sol[0:6])\n",
        "    number_units_bits = BitArray(ga_sol[6:]) \n",
        "    win_size = win_size_bits.uint\n",
        "    number_units = number_units_bits.uint\n",
        "    print('\\nWindow Size: ', win_size, ', Num of Units: ', number_units)\n",
        "    \n",
        "    \n",
        "    if win_size == 0 or number_units == 0:\n",
        "        return 100, \n",
        "    \n",
        "    \n",
        "    A,B = prepare(x_train,win_size)\n",
        "    A_train, A_val, B_train, B_val = split(A, B, test_size = 0.20, random_state = 1120)\n",
        "    \n",
        "    \n",
        "    inputs = Input(shape=(win_size,1))\n",
        "    A = LSTM(number_units, input_shape=(win_size,1))(inputs)\n",
        "    predictions = Dense(1, activation='relu')(A)\n",
        "    model = Model(inputs=inputs, outputs=predictions)\n",
        "    #model = tflearn.DNN(predictions, tensorboard_verbose=3, tensorboard_dir=\"logs\")\n",
        "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
        "    model.fit(A_train, B_train, epochs=5, batch_size=10,shuffle=True)\n",
        "    B_pred = model.predict(A_val)\n",
        "    #model.save('./ZtrainedNet/final-model.tfl')      \n",
        "    rmse = np.sqrt(mean_squared_error(B_val, B_pred))\n",
        "    print('Validation RMSE: ', rmse,'\\n')    \n",
        "    return rmse,\n",
        "\n",
        "population_size = 10\n",
        "num_generations = 5\n",
        "gene_length = 12\n",
        "\n",
        "creator.create('FitnessMax', base.Fitness, weights = (-1.0,))\n",
        "creator.create('Individual', list , fitness = creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register('binary', bernoulli.rvs, 0.5)\n",
        "toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
        "toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
        "\n",
        "toolbox.register('mate', tools.cxOrdered)\n",
        "toolbox.register('mutate', tools.mutShuffleIndexes, indpbb = 0.6)\n",
        "toolbox.register('select', tools.selRoulette)\n",
        "toolbox.register('evaluate', evaluate)\n",
        "\n",
        "\n",
        "population = toolbox.population(n = population_size)\n",
        "r = algorithms.eaSimple(population, toolbox, cxpb = 0.4, mutpb = 0.1, ngen = num_generations, verbose = False)\n",
        "\n",
        "\n",
        "best_individuals = tools.selBest(population,k = 1)\n",
        "best_win_size = None\n",
        "best_number_units = None\n",
        "\n",
        "for bi in best_individuals:\n",
        "    win_size_bits = BitArray(bi[0:6])\n",
        "    number_units_bits = BitArray(bi[6:]) \n",
        "    best_win_size = win_size_bits.uint\n",
        "    best_number_units = number_units_bits.uint\n",
        "    print('\\nWindow Size: ', best_win_size, ', Num of Units: ', best_number_units)\n",
        "\n",
        "\n",
        "A_train,B_train = prepare(x_train,best_win_size)\n",
        "A_test, B_test = prepare(X_test,best_win_size)\n",
        "\n",
        "inputs = Input(shape=(best_win_size,1))\n",
        "A = LSTM(best_number_units, input_shape=(best_win_size,1))(inputs)\n",
        "predictions = Dense(1, activation='relu')(A)\n",
        "model = Model(inputs = inputs, outputs = predictions)\n",
        "model.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model.fit(A_train, B_train, epochs=5, batch_size=10,shuffle=True)\n",
        "B_pred = model.predict(A_test)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(B_test, B_pred))\n",
        "print('Test RMSE: ', rmse)"
      ],
      "metadata": {
        "id": "0QjOA3KdleH4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ffe082d-6994-4ac7-8e55-6254d82e6f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deap in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.21.6)\n",
            "Requirement already satisfied: bitstring in /usr/local/lib/python3.7/dist-packages (3.1.9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  RuntimeWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Window Size:  36 , Num of Units:  11\n",
            "Epoch 1/5\n",
            "2567/2567 [==============================] - 13s 4ms/step - loss: 1473231.3750\n",
            "Epoch 2/5\n",
            "2567/2567 [==============================] - 9s 4ms/step - loss: 1459484.3750\n",
            "Epoch 3/5\n",
            "2567/2567 [==============================] - 9s 4ms/step - loss: 1447928.5000\n",
            "Epoch 4/5\n",
            "2567/2567 [==============================] - 9s 4ms/step - loss: 1437464.1250\n",
            "Epoch 5/5\n",
            "2567/2567 [==============================] - 10s 4ms/step - loss: 1428146.3750\n",
            "Validation RMSE:  1266.63667768132 \n",
            "\n",
            "\n",
            "Window Size:  34 , Num of Units:  15\n",
            "Epoch 1/5\n",
            "2568/2568 [==============================] - 68s 4ms/step - loss: 1524133.8750\n",
            "Epoch 2/5\n",
            "2568/2568 [==============================] - 11s 4ms/step - loss: 1524134.0000\n",
            "Epoch 3/5\n",
            "2568/2568 [==============================] - 11s 4ms/step - loss: 1524132.3750\n",
            "Epoch 4/5\n",
            "2568/2568 [==============================] - 11s 4ms/step - loss: 1524133.8750\n",
            "Epoch 5/5\n",
            "2568/2568 [==============================] - 11s 4ms/step - loss: 1524131.6250\n",
            "Validation RMSE:  1225.136970293549 \n",
            "\n",
            "\n",
            "Window Size:  9 , Num of Units:  49\n",
            "Epoch 1/5\n",
            "2570/2570 [==============================] - 11s 4ms/step - loss: 1505781.8750\n",
            "Epoch 2/5\n",
            "2570/2570 [==============================] - 9s 4ms/step - loss: 1466663.6250\n",
            "Epoch 3/5\n",
            "2570/2570 [==============================] - 9s 4ms/step - loss: 1443045.2500\n",
            "Epoch 4/5\n",
            "2570/2570 [==============================] - 9s 4ms/step - loss: 1429600.1250\n",
            "Epoch 5/5\n",
            "2570/2570 [==============================] - 10s 4ms/step - loss: 1422237.7500\n",
            "Validation RMSE:  1161.5800118590114 \n",
            "\n",
            "\n",
            "Window Size:  38 , Num of Units:  10\n",
            "Epoch 1/5\n",
            "2567/2567 [==============================] - 13s 4ms/step - loss: 1516513.3750\n",
            "Epoch 2/5\n",
            "2567/2567 [==============================] - 11s 4ms/step - loss: 1516512.3750\n",
            "Epoch 3/5\n",
            "2567/2567 [==============================] - 11s 4ms/step - loss: 1516512.8750\n",
            "Epoch 4/5\n",
            "2567/2567 [==============================] - 11s 4ms/step - loss: 1516511.8750\n",
            "Epoch 5/5\n",
            "2567/2567 [==============================] - 11s 4ms/step - loss: 1516513.2500\n",
            "Validation RMSE:  1237.8891987704446 \n",
            "\n",
            "\n",
            "Window Size:  23 , Num of Units:  2\n",
            "Epoch 1/5\n",
            "2568/2568 [==============================] - 10s 3ms/step - loss: 1515479.7500\n",
            "Epoch 2/5\n",
            "2568/2568 [==============================] - 9s 3ms/step - loss: 1511756.3750\n",
            "Epoch 3/5\n",
            "2568/2568 [==============================] - 9s 3ms/step - loss: 1508262.6250\n",
            "Epoch 4/5\n",
            "2568/2568 [==============================] - 9s 3ms/step - loss: 1504867.2500\n",
            "Epoch 5/5\n",
            "2568/2568 [==============================] - 8s 3ms/step - loss: 1501585.0000\n",
            "Validation RMSE:  1233.563478745959 \n",
            "\n",
            "\n",
            "Window Size:  14 , Num of Units:  34\n",
            "Epoch 1/5\n",
            "2569/2569 [==============================] - 12s 4ms/step - loss: 1550892.1250\n",
            "Epoch 2/5\n",
            "2569/2569 [==============================] - 10s 4ms/step - loss: 1519190.2500\n",
            "Epoch 3/5\n",
            "2569/2569 [==============================] - 10s 4ms/step - loss: 1496772.6250\n",
            "Epoch 4/5\n",
            "2569/2569 [==============================] - 10s 4ms/step - loss: 1480841.6250\n",
            "Epoch 5/5\n",
            "2569/2569 [==============================] - 10s 4ms/step - loss: 1469879.5000\n",
            "Validation RMSE:  1101.140315758779 \n",
            "\n",
            "\n",
            "Window Size:  48 , Num of Units:  60\n",
            "Epoch 1/5\n",
            "2566/2566 [==============================] - 12s 4ms/step - loss: 1452392.2500\n",
            "Epoch 2/5\n",
            "2566/2566 [==============================] - 11s 4ms/step - loss: 1411600.3750\n",
            "Epoch 3/5\n",
            "2566/2566 [==============================] - 11s 4ms/step - loss: 1389752.5000\n",
            "Epoch 4/5\n",
            "2566/2566 [==============================] - 11s 4ms/step - loss: 1378901.7500\n",
            "Epoch 5/5\n",
            "2566/2566 [==============================] - 11s 4ms/step - loss: 1380225.0000\n",
            "Validation RMSE:  1233.9422367406312 \n",
            "\n",
            "\n",
            "Window Size:  41 , Num of Units:  34\n",
            "Epoch 1/5\n",
            "2567/2567 [==============================] - 13s 5ms/step - loss: 1505372.5000\n",
            "Epoch 2/5\n",
            "2567/2567 [==============================] - 12s 5ms/step - loss: 1474039.8750\n",
            "Epoch 3/5\n",
            "2567/2567 [==============================] - 12s 5ms/step - loss: 1452755.8750\n",
            "Epoch 4/5\n",
            "2567/2567 [==============================] - 12s 5ms/step - loss: 1444895.8750\n",
            "Epoch 5/5\n",
            "2567/2567 [==============================] - 12s 5ms/step - loss: 1430677.1250\n",
            "Validation RMSE:  1176.7509238923856 \n",
            "\n",
            "\n",
            "Window Size:  1 , Num of Units:  44\n",
            "Epoch 1/5\n",
            "2570/2570 [==============================] - 10s 3ms/step - loss: 1517487.6250\n",
            "Epoch 2/5\n",
            "2570/2570 [==============================] - 9s 3ms/step - loss: 1517489.8750\n",
            "Epoch 3/5\n",
            "2570/2570 [==============================] - 9s 3ms/step - loss: 1517489.2500\n",
            "Epoch 4/5\n",
            "2570/2570 [==============================] - 9s 3ms/step - loss: 1517487.3750\n",
            "Epoch 5/5\n",
            "2570/2570 [==============================] - 9s 3ms/step - loss: 1517490.7500\n",
            "Validation RMSE:  1239.1842327297077 \n",
            "\n",
            "\n",
            "Window Size:  57 , Num of Units:  29\n",
            "Epoch 1/5\n",
            "2566/2566 [==============================] - 14s 5ms/step - loss: 1463523.7500\n",
            "Epoch 2/5\n",
            "2566/2566 [==============================] - 12s 5ms/step - loss: 1435210.6250\n",
            "Epoch 3/5\n",
            "2566/2566 [==============================] - 12s 5ms/step - loss: 1414541.0000\n",
            "Epoch 4/5\n",
            "2566/2566 [==============================] - 12s 5ms/step - loss: 1399139.0000\n",
            "Epoch 5/5\n",
            "2566/2566 [==============================] - 12s 5ms/step - loss: 1388721.3750\n",
            "Validation RMSE:  1246.1552333557559 \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-150e8c8adb74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopulation_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meaSimple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcxpb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutpb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_generations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deap/algorithms.py\u001b[0m in \u001b[0;36meaSimple\u001b[0;34m(population, toolbox, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Vary the pool of individuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0moffspring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvarAnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffspring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcxpb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutpb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# Evaluate the individuals with an invalid fitness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deap/algorithms.py\u001b[0m in \u001b[0;36mvarAnd\u001b[0;34m(population, toolbox, cxpb, mutpb)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffspring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmutpb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0moffspring\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffspring\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0moffspring\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: mutShuffleIndexes() got an unexpected keyword argument 'indpbb'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Genetic Algorithm\n"
      ],
      "metadata": {
        "id": "Km0uiosLfmTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deap\n",
        "!pip install bitstring\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split as split\n",
        "\n",
        "from keras.layers import LSTM, Input, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "from deap import base, creator, tools, algorithms\n",
        "from scipy.stats import bernoulli\n",
        "from bitstring import BitArray\n",
        "\n",
        "np.random.seed(1120)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeZ7KAiJtOSF",
        "outputId": "d65e0de9-173d-46dc-b6e7-63dad178ac15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deap in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.21.6)\n",
            "Requirement already satisfied: bitstring in /usr/local/lib/python3.7/dist-packages (3.1.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_test_ga = X_test\n",
        "# x_train_ga -> train_data\n",
        "# y_ga = y_train\n",
        "\n",
        "def prepare_dataset(data, window_size):\n",
        "    X, Y = np.empty((0,window_size)), np.empty((0))\n",
        "    for i in range(len(data)-window_size-1):\n",
        "        X = np.vstack([X,data[i:(i + window_size),0]])\n",
        "        Y = np.append(Y,data[i + window_size,0])   \n",
        "    X = np.reshape(X,(len(X),window_size,1))\n",
        "    Y = np.reshape(Y,(len(Y),1))\n",
        "    return X, Y\n",
        "\n",
        "X_train,y_train = prepare_dataset(x_train_ga, 3)\n",
        "print(X_train)\n",
        "print(y_train)"
      ],
      "metadata": {
        "id": "vxtSH1Bpfo3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "082319dc-f390-4e18-e8e6-b77b74666ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[   0.]\n",
            "  [   0.]\n",
            "  [   0.]]\n",
            "\n",
            " [[   0.]\n",
            "  [   0.]\n",
            "  [   0.]]\n",
            "\n",
            " [[   0.]\n",
            "  [   0.]\n",
            "  [ 576.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[   0.]\n",
            "  [1135.]\n",
            "  [   0.]]\n",
            "\n",
            " [[1135.]\n",
            "  [   0.]\n",
            "  [   0.]]\n",
            "\n",
            " [[   0.]\n",
            "  [   0.]\n",
            "  [   0.]]]\n",
            "[[  0.]\n",
            " [576.]\n",
            " [  0.]\n",
            " ...\n",
            " [  0.]\n",
            " [  0.]\n",
            " [429.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate(ga_individual_solution):  \n",
        "    \n",
        "    # Decode the Genetic Algorithm solution to get the window size and number of bits\n",
        "    window_size_bits = BitArray(ga_individual_solution[0:6])\n",
        "    num_units_bits = BitArray(ga_individual_solution[6:]) \n",
        "    window_size = window_size_bits.uint\n",
        "    num_of_units = num_units_bits.uint\n",
        "    print('\\nWindow Size: ', window_size, ', Num of Units: ', num_of_units)\n",
        "    \n",
        "    # Return fitness score of 100 if window_size or num_unit is zero\n",
        "    if window_size == 0 or num_of_units == 0:\n",
        "        return 100, \n",
        "    \n",
        "    # Segment the train_data based on new window_size; \n",
        "    # Split the dataset into train set(80) and validation set(20)\n",
        "    X_data,Y_data = prepare_dataset(x_train_ga,window_size)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_data, Y_data, test_size = 0.20, random_state = 1120)\n",
        "    \n",
        "    # Design an LSTM model to train on training data and predict on validation data\n",
        "    input_ph = Input(shape=(window_size,1))\n",
        "    x = LSTM(num_of_units, input_shape=(window_size,1))(input_ph)\n",
        "    predicted_values = Dense(1, activation='tanh')(x)\n",
        "    model = Model(inputs=input_ph, outputs=predicted_values)\n",
        "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=20,shuffle=True)\n",
        "    y_pred = model.predict(X_val)\n",
        "    \n",
        "    # Calculate the RMSE score as fitness score for GA\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    print('Validation RMSE: ', rmse,'\\n')\n",
        "    \n",
        "    return rmse,"
      ],
      "metadata": {
        "id": "9wgmUeiNraEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "population_size = 4\n",
        "num_generations = 4\n",
        "gene_length = 10\n",
        "\n",
        "#Implementation of Genetic Algorithm using DEAP python library.\n",
        "\n",
        "#Since we try to minimise the loss values, we use the negation of the root mean squared loss as fitness function.\n",
        "creator.create('FitnessMax', base.Fitness, weights = (-1.0,))\n",
        "creator.create('Individual', list , fitness = creator.FitnessMax)\n",
        "\n",
        "#initialize the variables as bernoilli random variables\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register('binary', bernoulli.rvs, 0.5)\n",
        "toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
        "toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
        "\n",
        "#Ordered cross-over used for mating\n",
        "toolbox.register('mate', tools.cxOrdered)\n",
        "#Shuffle mutation to reorder the chromosomes\n",
        "toolbox.register('mutate', tools.mutShuffleIndexes, indpb = 0.6)\n",
        "#use roulette wheel selection algorithm\n",
        "toolbox.register('select', tools.selRoulette)\n",
        "#training function used for evaluating fitness of individual solution.\n",
        "toolbox.register('evaluate', train_evaluate)\n",
        "\n",
        "population = toolbox.population(n = population_size)\n",
        "r = algorithms.eaSimple(population, toolbox, cxpb = 0.4, mutpb = 0.1, ngen = num_generations, verbose = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECJVC7gcroGL",
        "outputId": "1785bb62-9b1c-41e4-8537-164f29ae1a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  RuntimeWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Window Size:  36 , Num of Units:  2\n",
            "Epoch 1/5\n",
            "1284/1284 [==============================] - 11s 4ms/step - loss: 1580696.5000\n",
            "Epoch 2/5\n",
            "1284/1284 [==============================] - 5s 4ms/step - loss: 1580484.2500\n",
            "Epoch 3/5\n",
            "1284/1284 [==============================] - 5s 4ms/step - loss: 1580432.8750\n",
            "Epoch 4/5\n",
            "1284/1284 [==============================] - 5s 4ms/step - loss: 1580425.2500\n",
            "Epoch 5/5\n",
            "1284/1284 [==============================] - 5s 4ms/step - loss: 1580424.7500\n",
            "Validation RMSE:  1234.4465291289002 \n",
            "\n",
            "\n",
            "Window Size:  56 , Num of Units:  8\n",
            "Epoch 1/5\n",
            "1283/1283 [==============================] - 8s 5ms/step - loss: 1584165.2500\n",
            "Epoch 2/5\n",
            "1283/1283 [==============================] - 6s 4ms/step - loss: 1584066.7500\n",
            "Epoch 3/5\n",
            "1283/1283 [==============================] - 6s 4ms/step - loss: 1584066.0000\n",
            "Epoch 4/5\n",
            "1283/1283 [==============================] - 6s 4ms/step - loss: 1584065.7500\n",
            "Epoch 5/5\n",
            "1283/1283 [==============================] - 6s 4ms/step - loss: 1584066.8750\n",
            "Validation RMSE:  1227.894756778584 \n",
            "\n",
            "\n",
            "Window Size:  60 , Num of Units:  9\n",
            "Epoch 1/5\n",
            "1283/1283 [==============================] - 7s 5ms/step - loss: 1597574.7500\n",
            "Epoch 2/5\n",
            "1283/1283 [==============================] - 6s 5ms/step - loss: 1597541.5000\n",
            "Epoch 3/5\n",
            "1283/1283 [==============================] - 6s 5ms/step - loss: 1597540.2500\n",
            "Epoch 4/5\n",
            "1283/1283 [==============================] - 6s 4ms/step - loss: 1597542.0000\n",
            "Epoch 5/5\n",
            "1283/1283 [==============================] - 6s 5ms/step - loss: 1597542.0000\n",
            "Validation RMSE:  1206.1496115379487 \n",
            "\n",
            "\n",
            "Window Size:  49 , Num of Units:  9\n",
            "Epoch 1/5\n",
            "1283/1283 [==============================] - 6s 4ms/step - loss: 1570273.3750\n",
            "Epoch 2/5\n",
            "1283/1283 [==============================] - 5s 4ms/step - loss: 1570234.7500\n",
            "Epoch 3/5\n",
            "1283/1283 [==============================] - 5s 4ms/step - loss: 1570235.5000\n",
            "Epoch 4/5\n",
            "1283/1283 [==============================] - 5s 4ms/step - loss: 1570235.0000\n",
            "Epoch 5/5\n",
            "1283/1283 [==============================] - 5s 4ms/step - loss: 1570235.5000\n",
            "Validation RMSE:  1249.5435205195408 \n",
            "\n",
            "\n",
            "Window Size:  63 , Num of Units:  9\n",
            "Epoch 1/5\n",
            "1283/1283 [==============================] - 9s 5ms/step - loss: 1603024.3750\n",
            "Epoch 2/5\n",
            "1283/1283 [==============================] - 6s 5ms/step - loss: 1602948.2500\n",
            "Epoch 3/5\n",
            "1283/1283 [==============================] - 6s 5ms/step - loss: 1602947.3750\n",
            "Epoch 4/5\n",
            "1283/1283 [==============================] - 6s 5ms/step - loss: 1602947.8750\n",
            "Epoch 5/5\n",
            "1283/1283 [==============================] - 6s 5ms/step - loss: 1602947.6250\n",
            "Validation RMSE:  1197.4662345900579 \n",
            "\n",
            "\n",
            "Window Size:  63 , Num of Units:  9\n",
            "Epoch 1/5\n",
            "1283/1283 [==============================] - 7s 5ms/step - loss: 1602989.7500\n",
            "Epoch 2/5\n",
            "1283/1283 [==============================] - 6s 5ms/step - loss: 1602948.7500\n",
            "Epoch 3/5\n",
            "1283/1283 [==============================] - 6s 5ms/step - loss: 1602948.5000\n",
            "Epoch 4/5\n",
            "1283/1283 [==============================] - 6s 5ms/step - loss: 1602947.7500\n",
            "Epoch 5/5\n",
            "1283/1283 [==============================] - 6s 5ms/step - loss: 1602947.7500\n",
            "Validation RMSE:  1197.4662275037997 \n",
            "\n",
            "\n",
            "Window Size:  36 , Num of Units:  2\n",
            "Epoch 1/5\n",
            "1284/1284 [==============================] - 7s 4ms/step - loss: 1580606.6250\n",
            "Epoch 2/5\n",
            "1284/1284 [==============================] - 5s 4ms/step - loss: 1580434.1250\n",
            "Epoch 3/5\n",
            "1284/1284 [==============================] - 5s 4ms/step - loss: 1580428.6250\n",
            "Epoch 4/5\n",
            "1284/1284 [==============================] - 5s 4ms/step - loss: 1580426.6250\n",
            "Epoch 5/5\n",
            "1284/1284 [==============================] - 5s 4ms/step - loss: 1580425.8750\n",
            "Validation RMSE:  1234.4465180699585 \n",
            "\n",
            "\n",
            "Window Size:  36 , Num of Units:  2\n",
            "Epoch 1/5\n",
            "1284/1284 [==============================] - 7s 4ms/step - loss: 1580662.8750\n",
            "Epoch 2/5\n",
            "1284/1284 [==============================] - 5s 4ms/step - loss: 1580436.3750\n",
            "Epoch 3/5\n",
            "1284/1284 [==============================] - 5s 4ms/step - loss: 1580428.1250\n",
            "Epoch 4/5\n",
            "1284/1284 [==============================] - 5s 4ms/step - loss: 1580426.5000\n",
            "Epoch 5/5\n",
            "1284/1284 [==============================] - 5s 4ms/step - loss: 1580425.7500\n",
            "Validation RMSE:  1234.4465508469275 \n",
            "\n",
            "\n",
            "Window Size:  56 , Num of Units:  8\n",
            "Epoch 1/5\n",
            "1283/1283 [==============================] - 8s 4ms/step - loss: 1584143.2500\n",
            "Epoch 2/5\n",
            "1283/1283 [==============================] - 6s 4ms/step - loss: 1584066.1250\n",
            "Epoch 3/5\n",
            "1283/1283 [==============================] - 6s 4ms/step - loss: 1584065.0000\n",
            "Epoch 4/5\n",
            "1283/1283 [==============================] - 6s 4ms/step - loss: 1584065.0000\n",
            "Epoch 5/5\n",
            "1283/1283 [==============================] - 6s 4ms/step - loss: 1584064.3750\n",
            "Validation RMSE:  1227.894753279363 \n",
            "\n",
            "\n",
            "Window Size:  14 , Num of Units:  4\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 6s 4ms/step - loss: 1574452.6250\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 5s 4ms/step - loss: 1574296.2500\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 4s 3ms/step - loss: 1574289.6250\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 4s 3ms/step - loss: 1574289.8750\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 4s 3ms/step - loss: 1574288.7500\n",
            "Validation RMSE:  1244.3585689413635 \n",
            "\n",
            "\n",
            "Window Size:  8 , Num of Units:  11\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 6s 3ms/step - loss: 1559635.7500\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 4s 3ms/step - loss: 1559601.2500\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 4s 3ms/step - loss: 1559602.8750\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 4s 3ms/step - loss: 1559603.0000\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 4s 3ms/step - loss: 1559601.7500\n",
            "Validation RMSE:  1268.4332069223922 \n",
            "\n",
            "\n",
            "Window Size:  36 , Num of Units:  10\n",
            "Epoch 1/5\n",
            "1284/1284 [==============================] - 7s 4ms/step - loss: 1580486.0000\n",
            "Epoch 2/5\n",
            "1284/1284 [==============================] - 5s 4ms/step - loss: 1580426.3750\n",
            "Epoch 3/5\n",
            "1284/1284 [==============================] - 5s 4ms/step - loss: 1580424.0000\n",
            "Epoch 4/5\n",
            "1284/1284 [==============================] - 10s 8ms/step - loss: 1580423.6250\n",
            "Epoch 5/5\n",
            "1284/1284 [==============================] - 10s 8ms/step - loss: 1580424.5000\n",
            "Validation RMSE:  1234.4463487713144 \n",
            "\n",
            "\n",
            "Window Size:  8 , Num of Units:  3\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 9s 5ms/step - loss: 1559699.6250\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 4s 3ms/step - loss: 1559605.1250\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 5s 4ms/step - loss: 1559603.1250\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 6s 5ms/step - loss: 1559603.1250\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 6s 5ms/step - loss: 1559604.0000\n",
            "Validation RMSE:  1268.4332293442853 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_individuals_data = tools.selBest(population,k = 1) #select top 1 solution\n",
        "optimal_window_size = None\n",
        "optimal_num_units = None\n",
        "\n",
        "for bi in optimal_individuals_data:\n",
        "    window_size_bits = BitArray(bi[0:6])\n",
        "    num_units_bits = BitArray(bi[6:]) \n",
        "    optimal_window_size = window_size_bits.uint\n",
        "    optimal_num_units = num_units_bits.uint\n",
        "    print('\\n Best Window Size: ', optimal_window_size, ', Best Num of Units: ', optimal_num_units)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gw6vZ3_wGST",
        "outputId": "4699594c-2d83-4ce2-e60c-bd25e42e1a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Best Window Size:  36 , Best Num of Units:  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hence train the model with the optimal number of lstm units and optimal window size for prediction\n",
        "X_train,y_train = prepare_dataset(x_train_ga,optimal_window_size)\n",
        "X_test, y_test = prepare_dataset(x_train_ga,optimal_window_size)\n",
        "\n",
        "inputs = Input(shape=(optimal_window_size,1))\n",
        "x = LSTM(optimal_num_units, input_shape=(optimal_window_size,1))(inputs)\n",
        "predictions = Dense(1, activation='tanh')(x)\n",
        "model = Model(inputs = inputs, outputs = predictions)\n",
        "model.compile(optimizer='adam',loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=20,shuffle=True)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print('Test RMSE: ', rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-VQNFi8wS66",
        "outputId": "d70d591a-cd7b-4898-e7c5-f49b3d96d1fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1605/1605 [==============================] - 8s 4ms/step - loss: 1569169.5000\n",
            "Epoch 2/5\n",
            "1605/1605 [==============================] - 7s 4ms/step - loss: 1569111.8750\n",
            "Epoch 3/5\n",
            "1605/1605 [==============================] - 6s 4ms/step - loss: 1569111.0000\n",
            "Epoch 4/5\n",
            "1605/1605 [==============================] - 7s 4ms/step - loss: 1569110.0000\n",
            "Epoch 5/5\n",
            "1605/1605 [==============================] - 6s 4ms/step - loss: 1569109.8750\n",
            "Test RMSE:  1252.6414063535658\n"
          ]
        }
      ]
    }
  ]
}